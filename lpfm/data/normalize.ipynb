{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data and save stats in a yaml file\n",
    "\n",
    "This uses the normalize function from the-well library. It stores the stats in a yaml file.\n",
    "The normalize function is taken from the [the-well](https://github.com/PolymathicAI/the_well/blob/master/scripts/compute_statistics.py) library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define the normalize function and imports\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import h5py as h5\n",
    "import yaml\n",
    "from the_well.data.datasets import WellDataset\n",
    "\n",
    "\n",
    "def compute_statistics(train_path: str | Path, stats_path: str | Path):\n",
    "    \"\"\"Compute the normalization constants for a dataset.\"\"\"\n",
    "    train_path = str(train_path)\n",
    "    stats_path = str(stats_path)\n",
    "\n",
    "    if os.path.isfile(stats_path):\n",
    "        print(f\"{stats_path} already exists. Skipping\")\n",
    "        return\n",
    "\n",
    "    ds = WellDataset(train_path, use_normalization=False)\n",
    "\n",
    "    counts = {}\n",
    "    means = {}\n",
    "    variances = {}\n",
    "    stds = {}\n",
    "    rmss = {}\n",
    "\n",
    "    counts_delta = {}\n",
    "    means_delta = {}\n",
    "    variances_delta = {}\n",
    "    stds_delta = {}\n",
    "    rmss_delta = {}\n",
    "\n",
    "    for p in ds.files_paths:\n",
    "        with h5.File(p, \"r\") as f:\n",
    "            for i in range(3):\n",
    "                ti = f\"t{i}_fields\"\n",
    "\n",
    "                for field in f[ti].attrs[\"field_names\"]:\n",
    "                    data = f[ti][field][:]\n",
    "                    data = torch.as_tensor(data, dtype=torch.float64)\n",
    "                    # Convert all NaNs to 0\n",
    "                    data = torch.nan_to_num(data, nan=0.0)\n",
    "                    count = math.prod(data.shape[: data.ndim - i])\n",
    "                    var, mean = torch.var_mean(\n",
    "                        data,\n",
    "                        dim=tuple(range(0, data.ndim - i)),\n",
    "                        unbiased=False,\n",
    "                    )\n",
    "\n",
    "                    if field in counts:\n",
    "                        counts[field].append(count)\n",
    "                        means[field].append(mean)\n",
    "                        variances[field].append(var)\n",
    "                    else:\n",
    "                        counts[field] = [count]\n",
    "                        means[field] = [mean]\n",
    "                        variances[field] = [var]\n",
    "\n",
    "                    if f[ti][field].attrs[\"time_varying\"]:\n",
    "                        delta = data[:, 1:] - data[:, :-1]\n",
    "                        del data\n",
    "                        count_delta = math.prod(delta.shape[: delta.ndim - i])\n",
    "                        var_delta, mean_delta = torch.var_mean(\n",
    "                            delta,\n",
    "                            dim=tuple(range(0, delta.ndim - i)),\n",
    "                            unbiased=False,\n",
    "                        )\n",
    "                        if field in counts_delta:\n",
    "                            counts_delta[field].append(count_delta)\n",
    "                            means_delta[field].append(mean_delta)\n",
    "                            variances_delta[field].append(var_delta)\n",
    "                        else:\n",
    "                            counts_delta[field] = [count_delta]\n",
    "                            means_delta[field] = [mean_delta]\n",
    "                            variances_delta[field] = [var_delta]\n",
    "\n",
    "    for field in counts:\n",
    "        weights = torch.as_tensor(counts[field], dtype=torch.int64)\n",
    "        weights = weights / weights.sum()\n",
    "        weights = torch.as_tensor(weights, dtype=torch.float64)\n",
    "\n",
    "        means[field] = torch.stack(means[field])\n",
    "        variances[field] = torch.stack(variances[field])\n",
    "\n",
    "        # https://wikipedia.org/wiki/Mixture_distribution#Moments\n",
    "        first_moment = torch.einsum(\"i...,i\", means[field], weights)\n",
    "        second_moment = torch.einsum(\n",
    "            \"i...,i\", variances[field] + means[field] ** 2, weights\n",
    "        )\n",
    "\n",
    "        mean = first_moment\n",
    "        std = (second_moment - first_moment**2).sqrt()\n",
    "        rms = second_moment.sqrt()\n",
    "\n",
    "        means[field] = mean.tolist()\n",
    "        stds[field] = std.tolist()\n",
    "        rmss[field] = rms.tolist()\n",
    "\n",
    "        if torch.all(std < 1e-4):\n",
    "            print(f\"The standard deviation {std} of the '{field}' field is abnormally low.\")\n",
    "        # assert torch.all(std > 1e-4), (\n",
    "        #     f\"The standard deviation of the '{field}' field is abnormally low.\"\n",
    "        # )\n",
    "\n",
    "        if field in counts_delta:\n",
    "            weights_delta = torch.as_tensor(counts_delta[field], dtype=torch.int64)\n",
    "            weights_delta = weights_delta / weights_delta.sum()\n",
    "            weights_delta = torch.as_tensor(weights_delta, dtype=torch.float64)\n",
    "\n",
    "            means_delta[field] = torch.stack(means_delta[field])\n",
    "            variances_delta[field] = torch.stack(variances_delta[field])\n",
    "\n",
    "            first_moment_delta = torch.einsum(\n",
    "                \"i...,i\", means_delta[field], weights_delta\n",
    "            )\n",
    "            second_moment_delta = torch.einsum(\n",
    "                \"i...,i\",\n",
    "                variances_delta[field] + means_delta[field] ** 2,\n",
    "                weights_delta,\n",
    "            )\n",
    "\n",
    "            mean_delta = first_moment_delta\n",
    "            std_delta = (second_moment_delta - first_moment_delta**2).sqrt()\n",
    "            rms_delta = second_moment_delta.sqrt()\n",
    "\n",
    "            means_delta[field] = mean_delta.tolist()\n",
    "            stds_delta[field] = std_delta.tolist()\n",
    "            rmss_delta[field] = rms_delta.tolist()\n",
    "\n",
    "            #  assert torch.all(std_delta > 1e-4), (\n",
    "            #     f\"The delta standard deviation of the '{field}' field is abnormally low.\"\n",
    "            # )\n",
    "            if torch.all(std_delta <= 1e-4):\n",
    "                print(f\"The delta standard deviation of the '{field}' field is abnormally low.\")\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": means,\n",
    "        \"std\": stds,\n",
    "        \"rms\": rmss,\n",
    "        \"mean_delta\": means_delta,\n",
    "        \"std_delta\": stds_delta,\n",
    "        \"rms_delta\": rmss_delta,\n",
    "    }\n",
    "\n",
    "    with open(stats_path, mode=\"x\", encoding=\"utf8\") as f:\n",
    "        yaml.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute the normalization constants for all datasets\"\"\"\n",
    "\n",
    "\n",
    "path = Path(\"C:/Users/zsa8rk/Coding/MetaPARC/data/datasets\")\n",
    "\n",
    "for dataset in path.glob(\"**/train\"):\n",
    "    if dataset.is_dir():\n",
    "        print(f\"Compute stats for: {dataset}\")\n",
    "        compute_statistics(dataset, dataset.parents[0] / \"stats.yaml\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

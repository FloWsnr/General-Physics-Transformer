{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Auto-detect display width\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)  # Format float numbers\n",
    "\n",
    "from lpfm.utils.plotting.plot_lossVsTime import LossVsTimePlotter\n",
    "\n",
    "base_dir = Path(\"/scratch/zsa8rk/logs\")\n",
    "\n",
    "# Get Mean, Median and STD from loss dataframes\n",
    "RUNS = [\n",
    "    \"m-main-4-1\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combined_stats(df, column_patterns, level=0):\n",
    "    \"\"\"\n",
    "    Calculate the mean, median, and standard deviation of columns that match specific patterns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing the data\n",
    "    column_patterns : list of str\n",
    "        List of patterns to match column names\n",
    "    level : int\n",
    "        Level of the column to match\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the combined statistics for each pattern\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for pattern in column_patterns:\n",
    "        # Find columns that match the pattern exactly\n",
    "        matching_cols = [col for col in df.columns.get_level_values(level) if col.startswith(pattern + '_') or col == pattern]\n",
    "        if matching_cols:\n",
    "            # Calculate statistics across matching columns\n",
    "            combined_mean = df[matching_cols].mean(axis=1).mean()\n",
    "            combined_median = df[matching_cols].median(axis=1).median()\n",
    "            combined_std = df[matching_cols].std(axis=1).mean()\n",
    "            results.append({\n",
    "                'Pattern': pattern,\n",
    "                'Combined Mean': combined_mean,\n",
    "                'Combined Median': combined_median,\n",
    "                'Combined Std': combined_std\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for run in RUNS:\n",
    "    eval_dir = base_dir / run / \"eval\"\n",
    "    loss_df = pd.read_csv(eval_dir / \"losses.csv\", header=0)\n",
    "\n",
    "    # # calc mean, median and std for each column\n",
    "    # mean_loss = loss_df.mean()\n",
    "    # median_loss = loss_df.median()\n",
    "    # std_loss = loss_df.std()\n",
    "\n",
    "    # # Create a DataFrame with the statistics\n",
    "    # stats_df = pd.DataFrame({\n",
    "    #     'Mean': mean_loss,\n",
    "    #     'Median': median_loss,\n",
    "    #     'Std': std_loss\n",
    "    # })\n",
    "    \n",
    "\n",
    "    # Example usage:\n",
    "    # Calculate combined means for different flow types\n",
    "    flow_patterns = [\n",
    "        'cylinder_sym_flow_water',\n",
    "        'cylinder_pipe_flow_water',\n",
    "        'object_periodic_flow_water',\n",
    "        'object_sym_flow_water',\n",
    "        'object_sym_flow_air',\n",
    "        'rayleigh_benard',\n",
    "        'rayleigh_benard_obstacle',\n",
    "        'twophase_flow',\n",
    "        'shear_flow',\n",
    "        'euler_multi_quadrants_periodicBC',\n",
    "        'heated_object_pipe_flow_air',\n",
    "        'cooled_object_pipe_flow_air',\n",
    "        'acoustic_scattering_inclusions'\n",
    "\n",
    "    ]\n",
    "\n",
    "    combined_means = calculate_combined_stats(loss_df, flow_patterns)\n",
    "\n",
    "    # Calculate overall statistics across all columns\n",
    "    overall_stats = pd.DataFrame([{\n",
    "        'Pattern': 'OVERALL',\n",
    "        'Combined Mean': np.nanmean(loss_df.values),\n",
    "        'Combined Median': np.nanmedian(loss_df.values),\n",
    "        'Combined Std': np.nanstd(loss_df.values)\n",
    "    }])\n",
    "\n",
    "    # Concatenate the overall stats with the pattern-specific stats\n",
    "    combined_means = pd.concat([combined_means, overall_stats], ignore_index=True)\n",
    "\n",
    "    display(combined_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combined_stats_rollout(df, column_patterns, level=0):\n",
    "    \"\"\"\n",
    "    Calculate statistics for multi-level columns while preserving the second level structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing multi-level column data\n",
    "    column_patterns : list of str\n",
    "        List of patterns to match first level column names\n",
    "    level : int\n",
    "        Level of the column to match (default=0 for first level)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the combined statistics for each pattern,\n",
    "        preserving the second level column structure\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    index = []\n",
    "    for pattern in column_patterns:\n",
    "        # Find columns that match the pattern exactly in the first level\n",
    "        matching_cols = [col for col in df.columns.get_level_values(level) if col.startswith(pattern + '_') or col == pattern]\n",
    "        if matching_cols:\n",
    "            # Get all second level columns for the matching first level columns\n",
    "            second_level_cols = df.columns.get_level_values(1).unique()\n",
    "            third_level_cols = df.columns.get_level_values(2).unique()\n",
    "            \n",
    "            # Calculate statistics for each second level column\n",
    "            for second_col in second_level_cols:\n",
    "                for third_col in third_level_cols:\n",
    "                    # Get all columns that match both the pattern and second level\n",
    "                    cols_to_combine = [col for col in df.columns \n",
    "                                    if col[0] in matching_cols and col[1] == second_col and col[2] == third_col]\n",
    "                    \n",
    "                    if cols_to_combine:\n",
    "                        index.append((pattern, second_col, third_col))\n",
    "                        # Calculate statistics across matching columns\n",
    "                        data.append(df[cols_to_combine].mean(axis=1))\n",
    "            \n",
    "    index = pd.MultiIndex.from_tuples(index, names=[\"pattern\", \"metric\", \"channel\"])\n",
    "    df = pd.DataFrame(data, index=index).T\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "for run in RUNS:\n",
    "    eval_dir = base_dir / run / \"eval\"\n",
    "    rollout_df = pd.read_csv(eval_dir / \"rollout_losses.csv\", header=[0,1,2])\n",
    "    single_step_df = pd.read_csv(eval_dir / \"single_step_losses.csv\", header=[0,1,2])\n",
    "\n",
    "\n",
    "    # Calculate combined means for different flow types\n",
    "    flow_patterns = [\n",
    "        'cylinder_sym_flow_water',\n",
    "        'cylinder_pipe_flow_water',\n",
    "        'object_periodic_flow_water',\n",
    "        'object_sym_flow_water',\n",
    "        'object_sym_flow_air',\n",
    "        'rayleigh_benard',\n",
    "        'rayleigh_benard_obstacle',\n",
    "        'twophase_flow',\n",
    "        'shear_flow',\n",
    "        'euler_multi_quadrants_periodicBC',\n",
    "        'heated_object_pipe_flow_air',\n",
    "        'cooled_object_pipe_flow_air',\n",
    "        'acoustic_scattering_inclusions'\n",
    "\n",
    "    ]\n",
    "    combined_df = calculate_combined_stats_rollout(rollout_df, column_patterns=flow_patterns)\n",
    "\n",
    "    # combined_means = calculate_combined_stats(rollout_df, flow_patterns, level=0)\n",
    "    # combined_means = calculate_combined_stats(single_step_df, flow_patterns, level=0)\n",
    "    #print(combined_df.head())\n",
    "    # display(combined_df)\n",
    "\n",
    "    data_mean = combined_df[\"cylinder_sym_flow_water\"][\"mean\"]\n",
    "    data_std = combined_df[\"cylinder_sym_flow_water\"][\"std\"]\n",
    "    # Plot the combined dfs over time\n",
    "    x_ticks = [0, 25, 50]\n",
    "    y_ticks = [0, 0.2]\n",
    "    plotter = LossVsTimePlotter(x_ticks=x_ticks, y_ticks=y_ticks)\n",
    "    plotter.plot(mean_loss=data_mean.values, std_loss=None)\n",
    "    plotter.legend(\"cylinder_sym_flow_water\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

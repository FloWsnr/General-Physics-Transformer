{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from safetensors import safe_open\n",
    "\n",
    "from gphyt.model.transformer.model import get_model as get_gphyt_model\n",
    "from gphyt.model.unet import get_model as get_unet_model\n",
    "from gphyt.data.phys_dataset import PhysicsDataset as GPhyTDataset\n",
    "\n",
    "from scOT.model import ScOT, ScOTConfig\n",
    "from scOT.problems.well_ds import PhysicsDataset as PoseidonDataset\n",
    "\n",
    "from dpot.models.dpot import DPOTNet\n",
    "from dpot.well_ds import PhysicsDataset as DPOTDataset\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def load_yaml(file_path: Path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "base_path = Path(\"/hpcwork/rwth1802/coding/General-Physics-Transformer/results\")\n",
    "\n",
    "def unet_model(path: Path) -> torch.nn.Module:\n",
    "\n",
    "    config = {\n",
    "        \"model_size\": \"UNet_M\"\n",
    "    }\n",
    "    model = get_unet_model(config)\n",
    "    cp = torch.load(path / \"best_model.pth\", map_location='cpu')\n",
    "    model_state_dict = cp[\"model_state_dict\"]\n",
    "    consume_prefix_in_state_dict_if_present(model_state_dict, \"module.\")\n",
    "    consume_prefix_in_state_dict_if_present(model_state_dict, \"_orig_mod.\")\n",
    "    model.load_state_dict(model_state_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "def gphyt_model(path: Path) -> torch.nn.Module:\n",
    "    config = load_yaml(path / \"config_eval.yaml\")\n",
    "    model = get_gphyt_model(config[\"model\"])\n",
    "    cp = torch.load(path / \"best_model.pth\", map_location='cpu')\n",
    "    model_state_dict = cp[\"model_state_dict\"]\n",
    "    consume_prefix_in_state_dict_if_present(model_state_dict, \"module.\")\n",
    "    consume_prefix_in_state_dict_if_present(model_state_dict, \"_orig_mod.\")\n",
    "    model.load_state_dict(model_state_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "def poseidon_model(path: Path) -> ScOT:\n",
    "    def get_model() -> ScOT:\n",
    "        m_config = {\n",
    "            \"num_heads\": [3, 6, 12, 24],\n",
    "            \"skip_connections\": [2, 2, 2, 0],\n",
    "            \"window_size\": 16,\n",
    "            \"patch_size\": 4,\n",
    "            \"mlp_ratio\": 4.0,\n",
    "            \"depths\": [8, 8, 8, 8],\n",
    "            \"embed_dim\": 96,\n",
    "        }\n",
    "        config = ScOTConfig(\n",
    "            image_size=128,\n",
    "            patch_size=m_config[\"patch_size\"],\n",
    "            num_channels=5,\n",
    "            num_out_channels=5,\n",
    "            embed_dim=m_config[\"embed_dim\"],\n",
    "            depths=m_config[\"depths\"],\n",
    "            num_heads=m_config[\"num_heads\"],\n",
    "            skip_connections=m_config[\"skip_connections\"],\n",
    "            window_size=m_config[\"window_size\"],\n",
    "            mlp_ratio=m_config[\"mlp_ratio\"],\n",
    "            qkv_bias=True,\n",
    "            hidden_dropout_prob=0.0,  # default\n",
    "            attention_probs_dropout_prob=0.0,  # default\n",
    "            drop_path_rate=0.0,\n",
    "            hidden_act=\"gelu\",\n",
    "            use_absolute_embeddings=False,\n",
    "            initializer_range=0.02,\n",
    "            layer_norm_eps=1e-5,\n",
    "            p=1,\n",
    "            channel_slice_list_normalized_loss=None,\n",
    "            residual_model=\"convnext\",\n",
    "            use_conditioning=True,\n",
    "            learn_residual=False,\n",
    "        )\n",
    "        model = ScOT(config)\n",
    "        return model\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    weights = {}\n",
    "    with safe_open(path / \"model.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            weights[key] = f.get_tensor(key)\n",
    "    consume_prefix_in_state_dict_if_present(weights, \"module.\")\n",
    "    consume_prefix_in_state_dict_if_present(weights, \"_orig_mod.\")\n",
    "    model.load_state_dict(weights, strict=True)\n",
    "    return model\n",
    "\n",
    "def dpot_model(path: Path) -> torch.nn.Module:\n",
    "\n",
    "    config = load_yaml(Path(\"/hpcwork/rwth1802/coding/DPOT/configs/eval_medium.yaml\"))\n",
    "\n",
    "    def get_model(config: dict) -> torch.nn.Module:\n",
    "        model = DPOTNet(\n",
    "            img_size=config[\"res\"],\n",
    "            patch_size=config[\"patch_size\"],\n",
    "            in_channels=config[\"num_channels\"],\n",
    "            in_timesteps=config[\"T_in\"],\n",
    "            out_timesteps=1,\n",
    "            out_channels=config[\"num_channels\"],\n",
    "            normalize=config[\"normalize\"],\n",
    "            embed_dim=config[\"width\"],\n",
    "            depth=config[\"n_layers\"],\n",
    "            n_blocks=config[\"n_blocks\"],\n",
    "            mlp_ratio=config[\"mlp_ratio\"],\n",
    "            out_layer_dim=config[\"out_layer_dim\"],\n",
    "            act=config[\"act\"],\n",
    "            n_cls=12,\n",
    "        )\n",
    "        return model\n",
    "    model = get_model(config)\n",
    "\n",
    "    data = torch.load(path / \"model_6.pth\", map_location=\"cpu\", weights_only=False)\n",
    "    model_dict = data[\"model\"]\n",
    "    consume_prefix_in_state_dict_if_present(model_dict, \"module.\")\n",
    "    consume_prefix_in_state_dict_if_present(model_dict, \"_orig_mod.\")\n",
    "    model.load_state_dict(model_dict, strict=True)\n",
    "    return model\n",
    "\n",
    "@torch.inference_mode()\n",
    "def gphyt_forward(model, sample, device) -> torch.Tensor:\n",
    "\n",
    "    xx, target = sample\n",
    "\n",
    "    xx = xx.to(device).unsqueeze(0)  # add batch dim\n",
    "    target = target.to(device).unsqueeze(0)  # add batch dim\n",
    "    predictions = []\n",
    "\n",
    "    # Perform autoregressive prediction\n",
    "    ar_steps = target.shape[1]  # num of timesteps\n",
    "    output = torch.tensor(0.0, device=device)  # Initialize for linter\n",
    "    for _ar_step in range(ar_steps):\n",
    "        if _ar_step == 0:\n",
    "            x = xx\n",
    "        else:\n",
    "            x = torch.cat(\n",
    "                (x[:, 1:, ...], output),\n",
    "                dim=1,\n",
    "            )  # remove first input step, append output step\n",
    "        output = model(x)\n",
    "        predictions.append(output)\n",
    "    predictions = torch.cat(predictions, dim=1)  # concat along time dimension\n",
    "    return predictions.squeeze(0).cpu() # T, H, W, C\n",
    "\n",
    "@torch.inference_mode()\n",
    "def poseidon_forward(model, sample, device) -> torch.Tensor:\n",
    "\n",
    "    xx = sample[\"pixel_values\"].to(device)  # (C, H, W)\n",
    "    target = sample[\"labels\"].to(device)  # (T, C, H, W)\n",
    "    times = sample[\"time\"].to(device)\n",
    "    xx = xx.unsqueeze(0)  # add batch dim\n",
    "    target = target.unsqueeze(0)  # add batch dim\n",
    "    times = times.unsqueeze(0)  # add batch dim\n",
    "    predictions = []\n",
    "\n",
    "    ar_steps = target.shape[1]  # num of timesteps\n",
    "    output = torch.tensor(0.0, device=device)  # Initialize for linter\n",
    "    for _ar_step in range(ar_steps):\n",
    "        if _ar_step == 0:\n",
    "            x = F.interpolate(\n",
    "                xx, size=(128, 128), mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "        else:\n",
    "            x = output\n",
    "\n",
    "        input = {\n",
    "            \"pixel_values\": x,\n",
    "            \"time\": times,\n",
    "        }\n",
    "        output = model(**input).output # (B, C, H, W)\n",
    "\n",
    "        real_output = F.interpolate(\n",
    "            output,\n",
    "            size=xx.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        predictions.append(real_output)\n",
    "    predictions = torch.stack(predictions, dim=1)  # B, T, C, H, W\n",
    "    return predictions.squeeze(0).cpu()  # T, C, H, W\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def dpot_forward(model, sample, device) -> torch.Tensor:\n",
    "\n",
    "    xx, target, _ = sample  # h, w, t, c\n",
    "    xx = xx.to(device)  # h, w, t, c\n",
    "    target = target.to(device)  # h, w, t, c\n",
    "    xx = xx.unsqueeze(0)  # add batch dim\n",
    "    target = target.unsqueeze(0)  # add batch dim\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Perform autoregressive prediction\n",
    "    ar_steps = target.shape[-2]  # num of timesteps\n",
    "    output = torch.tensor(0.0, device=device)  # Initialize for linter\n",
    "    for _ar_step in range(ar_steps):\n",
    "        if _ar_step == 0:\n",
    "            x = xx\n",
    "            x = rearrange(x, \"B H W T C -> (B T) C H W\")  # (B*T, C, H, W)\n",
    "            x = F.interpolate(\n",
    "                x, size=(128, 128), mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            x = rearrange(x, \"(B T) C H W -> B H W T C\", B=1)  # (B, H, W, T, C)\n",
    "        else:\n",
    "            x = torch.cat(\n",
    "                (x[..., 1:, :], output),\n",
    "                dim=-2,\n",
    "            )  # remove first input step, append output step\n",
    "        output, _ = model(x)  # (B, H, W, 1, C)\n",
    "        predictions.append(output)\n",
    "    predictions = torch.cat(predictions, dim=-2)  # concat along time dimension\n",
    "    # reverse interpolation\n",
    "    predictions = rearrange(predictions, \"B H W T C -> (B T) C H W\")  # (B*T, C, H, W)\n",
    "    predictions = F.interpolate(\n",
    "        predictions,\n",
    "        size=(xx.shape[1], xx.shape[2]),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    predictions = rearrange(predictions, \"(B T) C H W -> B H W T C\", B=1)  # (B, H, W, T, C)\n",
    "\n",
    "    return predictions.squeeze(0).cpu()  # H, W, T, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "data_dir = Path(\"/hpcwork/rwth1802/coding/General-Physics-Transformer/data/datasets\")\n",
    "name = \"euler_multi_quadrants_periodicBC\"\n",
    "ar_steps = 24\n",
    "stride = 1\n",
    "sample_idx = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# UNet\n",
    "unet = unet_model(base_path / \"unet-m-04\")\n",
    "unet.eval()\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPHYT\n",
    "gphyt = gphyt_model(base_path / \"m-main-03\")\n",
    "gphyt.eval()\n",
    "gphyt.to(device)\n",
    "\n",
    "dataset_gphyt = GPhyTDataset(\n",
    "    data_dir / name / \"data/test\",\n",
    "    n_steps_input=4,\n",
    "    n_steps_output=ar_steps,\n",
    "    dt_stride=stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poseidon\n",
    "poseidon = poseidon_model(base_path / \"poseidon\")\n",
    "poseidon.eval()\n",
    "poseidon.to(device)\n",
    "dataset_poseidon = PoseidonDataset(\n",
    "    data_dir / name / \"data/test\",\n",
    "    n_output_steps=ar_steps,\n",
    "    dt_stride=stride,\n",
    "    train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# DPOT\n",
    "dpot = dpot_model(base_path / \"dpot\")\n",
    "dataset_dpot = DPOTDataset(\n",
    "    data_dir / name / \"data/test\",\n",
    "    T_in=4,\n",
    "    T_out=ar_steps,\n",
    "    dt_stride=stride,\n",
    "    train=False,\n",
    "    use_normalization=True\n",
    ")\n",
    "dpot.eval()\n",
    "dpot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample:\n",
    "sample_gphyt = dataset_gphyt[sample_idx]\n",
    "sample_poseidon = dataset_poseidon[sample_idx]\n",
    "sample_dpot = dataset_dpot[sample_idx] # xx (H, W, T, C), target, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction loop\n",
    "pred_unet = gphyt_forward(unet, sample_gphyt, device)  # T, H, W, C\n",
    "pred_gphyt = gphyt_forward(gphyt, sample_gphyt, device)  # T, H, W, C\n",
    "pred_poseidon = poseidon_forward(poseidon, sample_poseidon, device)  # T, C, H, W\n",
    "pred_dpot = dpot_forward(dpot, sample_dpot, device)  # H, W, T, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = sample_gphyt[1]  # T, H, W, C\n",
    "# rearrange poseidon prediction to T, H, W, C\n",
    "pred_poseidon = rearrange(pred_poseidon, \"T C H W -> T H W C\")\n",
    "# rearrange dpot prediction to T, H, W, C\n",
    "pred_dpot = rearrange(pred_dpot, \"H W T C -> T H W C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_rollout(\n",
    "    gt: torch.Tensor,\n",
    "    pred: torch.Tensor,\n",
    "    save_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Visualize the model predictions for a trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to numpy and transpose to match visualization format\n",
    "    predictions = pred.cpu().numpy()\n",
    "    ground_truth = gt.cpu().numpy()\n",
    "\n",
    "    # Transpose to match visualization format (T, H, W, C) -> (T, W, H, C)\n",
    "    predictions = predictions.transpose(0, 2, 1, 3)\n",
    "    ground_truth = ground_truth.transpose(0, 2, 1, 3)\n",
    "\n",
    "    # Calculate velocity magnitude\n",
    "    vel_mag_pred = np.linalg.norm(predictions[..., -2:], axis=-1)\n",
    "    vel_mag_gt = np.linalg.norm(ground_truth[..., -2:], axis=-1)\n",
    "\n",
    "    # Add velocity magnitude as a new channel\n",
    "    predictions = np.concatenate([predictions, vel_mag_pred[..., None]], axis=-1)\n",
    "    ground_truth = np.concatenate([ground_truth, vel_mag_gt[..., None]], axis=-1)\n",
    "\n",
    "    # Field names and colormaps\n",
    "    field_names = [\n",
    "        (\"pressure\", \"inferno\"),\n",
    "        (\"density\", \"viridis\"),\n",
    "        (\"temperature\", \"magma\"),\n",
    "        (\"velocity_x\", \"viridis\"),\n",
    "        (\"velocity_y\", \"viridis\"),\n",
    "        (\"velocity_mag\", \"viridis\"),\n",
    "    ]\n",
    "\n",
    "    # Create save directory if needed\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Visualize each field\n",
    "    for i, (field, colormap) in enumerate(field_names):\n",
    "        # Get min and max values for consistent color scaling\n",
    "        vmin = min(np.nanmin(predictions[..., i]), np.nanmin(ground_truth[..., i]))\n",
    "        vmax = max(np.nanmax(predictions[..., i]), np.nanmax(ground_truth[..., i]))\n",
    "\n",
    "        for t in range(predictions.shape[0]):\n",
    "            # Normalize the data to 0-1 range for colormap\n",
    "            pred_norm = (predictions[t, ..., i] - vmin) / (vmax - vmin)\n",
    "            gt_norm = (ground_truth[t, ..., i] - vmin) / (vmax - vmin)\n",
    "\n",
    "            # Apply viridis colormap\n",
    "            colormap = plt.get_cmap(colormap)\n",
    "            pred_rgb = colormap(pred_norm)[..., :3]  # Get RGB channels\n",
    "            gt_rgb = colormap(gt_norm)[..., :3]  # Get RGB channels\n",
    "\n",
    "            # Convert to uint8 for PIL\n",
    "            pred_rgb = (pred_rgb * 255).astype(np.uint8)\n",
    "            gt_rgb = (gt_rgb * 255).astype(np.uint8)\n",
    "\n",
    "            # Create PIL images\n",
    "            pred_img = Image.fromarray(pred_rgb)\n",
    "            gt_img = Image.fromarray(gt_rgb)\n",
    "\n",
    "            # Save prediction\n",
    "            pred_path = save_path / f\"{field}_pred_t{t}.png\"\n",
    "            pred_img.save(pred_path)\n",
    "\n",
    "            # Save ground truth\n",
    "            gt_path = save_path / f\"{field}_gt_t{t}.png\"\n",
    "            gt_img.save(gt_path)\n",
    "\n",
    "\n",
    "img_path = Path(\n",
    "    \"/hpcwork/rwth1802/coding/General-Physics-Transformer/results/01_new_plots/visualizations\"\n",
    ")\n",
    "\n",
    "visualize_rollout(\n",
    "    ground_truth,\n",
    "    pred_gphyt,\n",
    "    save_path=img_path / name / \"gphyt\",\n",
    ")\n",
    "visualize_rollout(\n",
    "    ground_truth,\n",
    "    pred_poseidon,\n",
    "    save_path=img_path / name / \"poseidon\",\n",
    ")\n",
    "visualize_rollout(\n",
    "    ground_truth,\n",
    "    pred_dpot,\n",
    "    save_path=img_path / name / \"dpot\",\n",
    ")\n",
    "visualize_rollout(\n",
    "    ground_truth,\n",
    "    pred_unet,\n",
    "    save_path=img_path / name / \"unet\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gphyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
